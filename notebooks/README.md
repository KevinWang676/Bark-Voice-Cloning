# ChatGLM2å¾®è°ƒæŒ‡å— ğŸ’¡
#### ChatGLM3å¾®è°ƒ[è§ä¸‹æ–¹](https://github.com/KevinWang676/Bark-Voice-Cloning/blob/main/notebooks/README.md#chatglm3%E5%BE%AE%E8%B0%83%E6%8C%87%E5%8D%97-)
#### AI Agentæ­å»º[è§ä¸‹æ–¹](https://github.com/KevinWang676/Bark-Voice-Cloning/tree/main/notebooks#ai-agent-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97-)
## 1. ç¯å¢ƒæ­å»º
### å®‰è£…ä¾èµ–
```
git clone https://github.com/THUDM/ChatGLM2-6B
cd ChatGLM2-6B
pip install -r requirements.txt
pip install rouge_chinese nltk jieba datasets
```
### ä¸‹è½½æ¨¡å‹
```
curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
sudo apt-get install git-lfs
sudo apt install build-essential
git clone https://huggingface.co/THUDM/chatglm2-6b
```

## 2. å‡†å¤‡æ•°æ®é›†

è‡ªå»ºæ•°æ®é›†è¯·å‚è€ƒ[train.json](https://github.com/KevinWang676/Bark-Voice-Cloning/blob/main/notebooks/train.json)åŠä»¥ä¸‹æ ¼å¼ï¼š
```json lines
{"prompt": "é•¿åŸh3é£æ‰‡ä¸è½¬ã€‚ç»§ç”µå™¨å¥½çš„ã€‚ä¿é™©ä¸å¥½çš„ä¼ æ„Ÿå™¨æ–°çš„é£æ‰‡ä¹Ÿæ–°çš„è¿™æ˜¯ä¸ºä»€ä¹ˆã€‚å°±æ˜¯ç»§ç”µå™¨ç¼ºä¸€ä¸ªä¿¡å·çº¿", "response": "ç”¨ç”µè„‘èƒ½è¯»æ•°æ®æµå—ï¼Ÿæ°´æ¸©å¤šå°‘", "history": []}
{"prompt": "95", "response": "ä¸Šä¸‹æ°´ç®¡æ¸©å·®æ€ä¹ˆæ ·å•Šï¼Ÿç©ºæ°”æ˜¯ä¸æ˜¯éƒ½æ’å¹²å‡€äº†å‘¢ï¼Ÿ", "history": [["é•¿åŸh3é£æ‰‡ä¸è½¬ã€‚ç»§ç”µå™¨å¥½çš„ã€‚ä¿é™©ä¸å¥½çš„ä¼ æ„Ÿå™¨æ–°çš„é£æ‰‡ä¹Ÿæ–°çš„è¿™æ˜¯ä¸ºä»€ä¹ˆã€‚å°±æ˜¯ç»§ç”µå™¨ç¼ºä¸€ä¸ªä¿¡å·çº¿", "ç”¨ç”µè„‘èƒ½è¯»æ•°æ®æµå—ï¼Ÿæ°´æ¸©å¤šå°‘"]]}
{"prompt": "æ˜¯çš„ã€‚ä¸Šä¸‹æ°´ç®¡éƒ½å¥½çš„", "response": "é‚£å°±è¦æ£€æŸ¥çº¿è·¯äº†ï¼Œä¸€èˆ¬é£æ‰‡ç»§ç”µå™¨æ˜¯ç”±ç”µè„‘æ§åˆ¶å¸åˆçš„ï¼Œå¦‚æœç”µè·¯å­˜åœ¨æ–­è·¯ï¼Œæˆ–è€…ç”µè„‘åäº†çš„è¯ä¼šå‡ºç°ç»§ç”µå™¨ä¸å¸åˆçš„æƒ…å†µï¼", "history": [["é•¿åŸh3é£æ‰‡ä¸è½¬ã€‚ç»§ç”µå™¨å¥½çš„ã€‚ä¿é™©ä¸å¥½çš„ä¼ æ„Ÿå™¨æ–°çš„é£æ‰‡ä¹Ÿæ–°çš„è¿™æ˜¯ä¸ºä»€ä¹ˆã€‚å°±æ˜¯ç»§ç”µå™¨ç¼ºä¸€ä¸ªä¿¡å·çº¿", "ç”¨ç”µè„‘èƒ½è¯»æ•°æ®æµå—ï¼Ÿæ°´æ¸©å¤šå°‘"], ["95", "ä¸Šä¸‹æ°´ç®¡æ¸©å·®æ€ä¹ˆæ ·å•Šï¼Ÿç©ºæ°”æ˜¯ä¸æ˜¯éƒ½æ’å¹²å‡€äº†å‘¢ï¼Ÿ"]]}
```
åˆ†åˆ«å‡†å¤‡è®­ç»ƒæ•°æ®é›† `train.json` å’ŒéªŒè¯æ•°æ®é›† `dev.json` å¹¶å°†å…¶ä¸Šä¼ è‡³ `ChatGLM2-6B` æ–‡ä»¶å¤¹ä¸‹

## 3. å¼€å§‹è®­ç»ƒ

åœ¨ç»ˆç«¯è¿è¡Œä»¥ä¸‹æŒ‡ä»¤ï¼Œå³å¯å¼€å§‹è®­ç»ƒ
```shell
bash train_chat.sh
```

**æ³¨æ„**ï¼šåŸ `train_chat.sh` æ–‡ä»¶ä¸­åŒ…å«ä»¥ä¸‹ä»£ç ï¼š
```
PRE_SEQ_LEN=128
LR=1e-2
NUM_GPUS=1

torchrun --standalone --nnodes=1 --nproc-per-node=$NUM_GPUS main.py \
    --do_train \
    --train_file $CHAT_TRAIN_DATA \
    --validation_file $CHAT_VAL_DATA \
    --preprocessing_num_workers 10 \
    --prompt_column prompt \
    --response_column response \
    --history_column history \
    --overwrite_cache \
    --model_name_or_path THUDM/chatglm2-6b \
    --output_dir $CHECKPOINT_NAME \
    --overwrite_output_dir \
    --max_source_length 256 \
    --max_target_length 256 \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --gradient_accumulation_steps 16 \
    --predict_with_generate \
    --max_steps 3000 \
    --logging_steps 10 \
    --save_steps 1000 \
    --learning_rate $LR \
    --pre_seq_len $PRE_SEQ_LEN \
    --quantization_bit 4
```
**åœ¨å¼€å§‹è®­ç»ƒå‰ï¼Œéœ€è¦å°†å…¶ç¼–è¾‘ä¸ºä»¥ä¸‹ç¤ºä¾‹ä»£ç **ï¼š
```
PRE_SEQ_LEN=128
LR=1e-2
NUM_GPUS=1

torchrun --standalone --nnodes=1 --nproc-per-node=$NUM_GPUS ptuning/main.py \
    --do_train \
    --train_file train.json \
    --validation_file dev.json \
    --preprocessing_num_workers 10 \
    --prompt_column prompt \
    --response_column response \
    --history_column history \
    --overwrite_cache \
    --model_name_or_path chatglm2-6b \
    --output_dir output_model \
    --overwrite_output_dir \
    --max_source_length 1024 \
    --max_target_length 1024 \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --gradient_accumulation_steps 16 \
    --predict_with_generate \
    --max_steps 600 \
    --logging_steps 10 \
    --save_steps 100 \
    --learning_rate $LR \
    --pre_seq_len $PRE_SEQ_LEN
```

P.S. ä»¥ä¸Šçš„ `train_chat.sh` æ–‡ä»¶åªæ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œå…·ä½“å‚æ•°è®¾ç½®è¯·æ ¹æ®ä¸åŒGPUçš„æ€§èƒ½è¿›è¡Œè°ƒèŠ‚ï¼›ChatGLM2å¾®è°ƒ[å®˜æ–¹æ•™ç¨‹](https://github.com/THUDM/ChatGLM2-6B/tree/main/ptuning)

# ChatGLM3å¾®è°ƒæŒ‡å— ğŸ“’

## 1. ç¯å¢ƒæ­å»º
### å®‰è£…ä¾èµ–
```
git clone https://github.com/THUDM/ChatGLM3
cd ChatGLM3
pip install -r requirements.txt
pip install transformers==4.34.0
apt install nvidia-cuda-toolkit
cd finetune_chatmodel_demo
pip install -r requirements.txt
cd ..
```
### ä¸‹è½½æ¨¡å‹
```
curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
sudo apt-get install git-lfs
sudo apt install build-essential
git clone https://huggingface.co/THUDM/chatglm3-6b
```
## 2. å‡†å¤‡æ•°æ®é›†

è‡ªå»ºæ•°æ®é›†è¯·å‚è€ƒ[train_linghua_new_v3.json](https://github.com/KevinWang676/Bark-Voice-Cloning/blob/main/notebooks/train_linghua_new_v3.json)åŠä»¥ä¸‹æ ¼å¼ï¼š
```json
[
  {
    "conversations": [
      {
        "role": "system",
        "content": "<system prompt text>"
      },
      {
        "role": "user",
        "content": "<user prompt text>"
      },
      {
        "role": "assistant",
        "content": "<assistant response text>"
      }, 
       // ... Muti Turn
      {
        "role": "user",
        "content": "<user prompt text>"
      },
      {
        "role": "assistant",
        "content": "<assistant response text>"
      }
    ]
  }
  // ...
]
```


å‡†å¤‡è®­ç»ƒæ•°æ®é›† `train.json` å¹¶å°†å…¶ä¸Šä¼ è‡³ `ChatGLM3` æ–‡ä»¶å¤¹ä¸‹

## 3. å¼€å§‹è®­ç»ƒ

åœ¨ç»ˆç«¯è¿è¡Œä»¥ä¸‹æŒ‡ä»¤ï¼Œå³å¯å¼€å§‹è®­ç»ƒ
```shell
bash finetune_chatmodel_demo/scripts/finetune_pt_multiturn.sh
```

**æ³¨æ„**ï¼šåŸ `finetune_pt_multiturn.sh` æ–‡ä»¶ä¸­åŒ…å«ä»¥ä¸‹ä»£ç ï¼š
```
#! /usr/bin/env bash

set -ex

PRE_SEQ_LEN=128
LR=2e-2
NUM_GPUS=1
MAX_SEQ_LEN=2048
DEV_BATCH_SIZE=1
GRAD_ACCUMULARION_STEPS=16
MAX_STEP=1000
SAVE_INTERVAL=500

DATESTR=`date +%Y%m%d-%H%M%S`
RUN_NAME=tool_alpaca_pt

BASE_MODEL_PATH=THUDM/chatglm3-6b
DATASET_PATH=formatted_data/tool_alpaca.jsonl
OUTPUT_DIR=output/${RUN_NAME}-${DATESTR}-${PRE_SEQ_LEN}-${LR}

mkdir -p $OUTPUT_DIR

torchrun --standalone --nnodes=1 --nproc_per_node=$NUM_GPUS finetune.py \
    --train_format multi-turn \
    --train_file $DATASET_PATH \
    --max_seq_length $MAX_SEQ_LEN \
    --preprocessing_num_workers 1 \
    --model_name_or_path $BASE_MODEL_PATH \
    --output_dir $OUTPUT_DIR \
    --per_device_train_batch_size $DEV_BATCH_SIZE \
    --gradient_accumulation_steps $GRAD_ACCUMULARION_STEPS \
    --max_steps $MAX_STEP \
    --logging_steps 1 \
    --save_steps $SAVE_INTERVAL \
    --learning_rate $LR \
    --pre_seq_len $PRE_SEQ_LEN 2>&1 | tee ${OUTPUT_DIR}/train.log
```
**åœ¨å¼€å§‹è®­ç»ƒå‰ï¼Œéœ€è¦å°†å…¶ç¼–è¾‘ä¸ºä»¥ä¸‹ç¤ºä¾‹ä»£ç **ï¼š
```
#! /usr/bin/env bash

set -ex

PRE_SEQ_LEN=128
LR=1e-2
NUM_GPUS=1
MAX_SEQ_LEN=2048
DEV_BATCH_SIZE=1
GRAD_ACCUMULARION_STEPS=16
MAX_STEP=700
SAVE_INTERVAL=100

DATESTR=`date +%Y%m%d-%H%M%S`
RUN_NAME=linghua_pt

BASE_MODEL_PATH=chatglm3-6b
DATASET_PATH=train.json
OUTPUT_DIR=output/${RUN_NAME}-${DATESTR}-${PRE_SEQ_LEN}-${LR}

mkdir -p $OUTPUT_DIR

torchrun --standalone --nnodes=1 --nproc_per_node=$NUM_GPUS finetune_chatmodel_demo/finetune.py \
    --train_format multi-turn \
    --train_file $DATASET_PATH \
    --max_seq_length $MAX_SEQ_LEN \
    --preprocessing_num_workers 1 \
    --model_name_or_path $BASE_MODEL_PATH \
    --output_dir $OUTPUT_DIR \
    --per_device_train_batch_size $DEV_BATCH_SIZE \
    --gradient_accumulation_steps $GRAD_ACCUMULARION_STEPS \
    --max_steps $MAX_STEP \
    --logging_steps 1 \
    --save_steps $SAVE_INTERVAL \
    --learning_rate $LR \
    --pre_seq_len $PRE_SEQ_LEN 2>&1 | tee ${OUTPUT_DIR}/train.log
```
P.S. ä»¥ä¸Šçš„ `finetune_pt_multiturn.sh` æ–‡ä»¶åªæ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œå…·ä½“å‚æ•°è®¾ç½®è¯·æ ¹æ®ä¸åŒGPUçš„æ€§èƒ½è¿›è¡Œè°ƒèŠ‚ï¼›ChatGLM3å¾®è°ƒ[å®˜æ–¹æ•™ç¨‹](https://github.com/THUDM/ChatGLM3/tree/main/finetune_chatmodel_demo)


# AI Agent ä½¿ç”¨æŒ‡å— ğŸŒŸ

## 1. ç¯å¢ƒæ­å»º
### å®‰è£…ä¾èµ–
```
git clone https://github.com/KevinWang676/modelscope-agent.git
cd modelscope-agent
pip install -r requirements.txt
mv modelscope_agent apps/agentfabric
apt-get update && apt-get install ffmpeg libsm6 libxext6  -y
cd apps/agentfabric
```
### API Keyè®¾ç½®
```
import os
os.environ["DASHSCOPE_API_KEY"] = "æ‚¨çš„DASHSCOPE_API_KEY"
```
æˆ–
`export DASHSCOPE_API_KEY=your_api_key`

## 2. å¼€å§‹ä½¿ç”¨
```
python app.py
```
