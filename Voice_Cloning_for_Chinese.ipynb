{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLClKUg72apRVkbyQ5fe5O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinWang676/Bark-Voice-Cloning/blob/main/Voice_Cloning_for_Chinese.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 中文声音克隆 Voice Cloning for Chinese"
      ],
      "metadata": {
        "id": "Uhhc4_stcdSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 配置环境 & 对音频切片处理"
      ],
      "metadata": {
        "id": "YZqH0DtGcsXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai-whisper\n",
        "! pip install modelscope\n",
        "! pip install tts-autolabel -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html"
      ],
      "metadata": {
        "id": "s2aAbOEPaVh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os._exit(00)"
      ],
      "metadata": {
        "id": "ZeWpsoG50qmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "from pathlib import Path\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "import torch\n",
        "import csv\n",
        "import whisper\n",
        "\n",
        "def split_long_audio(model, filepaths, character_name, save_dir=\"data_dir\", out_sr=44100):\n",
        "    if isinstance(filepaths, str):\n",
        "        filepaths = [filepaths]\n",
        "\n",
        "    for file_idx, filepath in enumerate(filepaths):\n",
        "\n",
        "        save_path = Path(save_dir) / character_name\n",
        "        save_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "        print(f\"Transcribing file {file_idx}: '{filepath}' to segments...\")\n",
        "        result = model.transcribe(filepath, word_timestamps=True, task=\"transcribe\", beam_size=5, best_of=5)\n",
        "        segments = result['segments']\n",
        "\n",
        "        wav, sr = librosa.load(filepath, sr=None, offset=0, duration=None, mono=True)\n",
        "        wav, _ = librosa.effects.trim(wav, top_db=20)\n",
        "        peak = np.abs(wav).max()\n",
        "        if peak > 1.0:\n",
        "            wav = 0.98 * wav / peak\n",
        "        wav2 = librosa.resample(wav, orig_sr=sr, target_sr=out_sr)\n",
        "        wav2 /= max(wav2.max(), -wav2.min())\n",
        "\n",
        "        for i, seg in enumerate(segments):\n",
        "            start_time = seg['start']\n",
        "            end_time = seg['end']\n",
        "            wav_seg = wav2[int(start_time * out_sr):int(end_time * out_sr)]\n",
        "            wav_seg_name = f\"{character_name}_{file_idx}_{i}.wav\"\n",
        "            out_fpath = save_path / wav_seg_name\n",
        "            wavfile.write(out_fpath, rate=out_sr, data=(wav_seg * np.iinfo(np.int16).max).astype(np.int16))"
      ],
      "metadata": {
        "id": "NdoD-ZnIaWhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_size = \"medium\"\n",
        "whisper_model = whisper.load_model(whisper_size)"
      ],
      "metadata": {
        "id": "yXrxpjEGaWlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_long_audio(whisper_model, \"test\", \"name\", \"dataset_raw\")"
      ],
      "metadata": {
        "id": "yTN4IRxOaWoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 需要新建三个文件夹，分别是：\"test_wavs\", \"output_training_data\", \"pretrain_work_dir\""
      ],
      "metadata": {
        "id": "ccQC4ZcWbtXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mv  -v ~./dataset_raw/test/* ~./test_wavs/"
      ],
      "metadata": {
        "id": "j6Mm7OWy081b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from modelscope.tools import run_auto_label\n",
        "\n",
        "input_wav = \"./test_wavs/\"\n",
        "output_data = \"./output_training_data/\"\n",
        "\n",
        "ret, report = run_auto_label(input_wav=input_wav, work_dir=output_data, resource_revision=\"v1.0.5\")"
      ],
      "metadata": {
        "id": "YpEmrdkgaU1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 训练"
      ],
      "metadata": {
        "id": "oImeaYwbcFOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from modelscope.metainfo import Trainers\n",
        "from modelscope.trainers import build_trainer\n",
        "from modelscope.utils.audio.audio_utils import TtsTrainType\n",
        "\n",
        "pretrained_model_id = 'damo/speech_personal_sambert-hifigan_nsf_tts_zh-cn_pretrain_16k'\n",
        "\n",
        "dataset_id = \"./output_training_data/\"\n",
        "pretrain_work_dir = \"./pretrain_work_dir/\"\n",
        "\n",
        "# 训练信息，用于指定需要训练哪个或哪些模型，这里展示AM和Vocoder模型皆进行训练\n",
        "# 目前支持训练：TtsTrainType.TRAIN_TYPE_SAMBERT, TtsTrainType.TRAIN_TYPE_VOC\n",
        "# 训练SAMBERT会以模型最新step作为基础进行finetune\n",
        "train_info = {\n",
        "    TtsTrainType.TRAIN_TYPE_SAMBERT: {  # 配置训练AM（sambert）模型\n",
        "        'train_steps': 202,               # 训练多少个step\n",
        "        'save_interval_steps': 200,       # 每训练多少个step保存一次checkpoint\n",
        "        'log_interval': 10               # 每训练多少个step打印一次训练日志\n",
        "    }\n",
        "}\n",
        "\n",
        "# 配置训练参数，指定数据集，临时工作目录和train_info\n",
        "kwargs = dict(\n",
        "    model=pretrained_model_id,                  # 指定要finetune的模型\n",
        "    model_revision = \"v1.0.6\",\n",
        "    work_dir=pretrain_work_dir,                 # 指定临时工作目录\n",
        "    train_dataset=dataset_id,                   # 指定数据集id\n",
        "    train_type=train_info                       # 指定要训练类型及参数\n",
        ")\n",
        "\n",
        "trainer = build_trainer(Trainers.speech_kantts_trainer,\n",
        "                        default_args=kwargs)\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "tzH2jcmxbV1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推理"
      ],
      "metadata": {
        "id": "l2rLYGwIcJ5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from modelscope.models.audio.tts import SambertHifigan\n",
        "from modelscope.pipelines import pipeline\n",
        "from modelscope.utils.constant import Tasks\n",
        "\n",
        "model_dir = os.path.abspath(\"./pretrain_work_dir\")\n",
        "\n",
        "custom_infer_abs = {\n",
        "    'voice_name':\n",
        "    'F7',\n",
        "    'am_ckpt':\n",
        "    os.path.join(model_dir, 'tmp_am', 'ckpt'),\n",
        "    'am_config':\n",
        "    os.path.join(model_dir, 'tmp_am', 'config.yaml'),\n",
        "    'voc_ckpt':\n",
        "    os.path.join(model_dir, 'orig_model', 'basemodel_16k', 'hifigan', 'ckpt'),\n",
        "    'voc_config':\n",
        "    os.path.join(model_dir, 'orig_model', 'basemodel_16k', 'hifigan',\n",
        "             'config.yaml'),\n",
        "    'audio_config':\n",
        "    os.path.join(model_dir, 'data', 'audio_config.yaml'),\n",
        "    'se_file':\n",
        "    os.path.join(model_dir, 'data', 'se', 'se.npy')\n",
        "}\n",
        "kwargs = {'custom_ckpt': custom_infer_abs}\n",
        "\n",
        "model_id = SambertHifigan(os.path.join(model_dir, \"orig_model\"), **kwargs)\n",
        "\n",
        "inference = pipeline(task=Tasks.text_to_speech, model=model_id)\n",
        "output = inference(input=\"大家好呀，欢迎使用滔滔智能的声音克隆产品！\")\n",
        "\n",
        "import IPython.display as ipd\n",
        "ipd.Audio(output[\"output_wav\"], rate=16000)\n"
      ],
      "metadata": {
        "id": "hBVxPrEpbgB-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}